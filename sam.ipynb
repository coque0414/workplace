{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coque0414/workplace/blob/master/sam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# SAM (Segment Anything Model)"
      ],
      "metadata": {
        "id": "3m-cS0_-3yyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 세그멘테이션"
      ],
      "metadata": {
        "id": "6ewwyYLcWo8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **이미지 세그멘테이션(Image Segmentation)** 기술은 컴퓨터가 디지털 이미지나 영상에서 데이터를 추출하고 해석할 수 있도록 하는 컴퓨터 비전 기술 중의 하나로, 이미지 내의 특정 객체를 픽셀 단위로 분리하는 기술\n",
        "\n",
        "> **객체 인식(Object Detection)** 기술은 이미지 내에서 특정 객체를 식별하고 그 위치를 파악하여 경계를 표시하는 컴퓨터 비전 기술  \n",
        "일반적으로 객체를 식별한 후에는 바운딩 박스라고 불리는 사각형을 그려 경계를 표시함\n",
        "\n",
        "상기 기술의 사용 순서는 **객체 인식 기술**을 사용한 후, 제안된 바운딩 박스 내부에 **이미지 세그멘테이션 기술**을 사용할 수 있음\n"
      ],
      "metadata": {
        "id": "0kwS7kcm4N2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 객체 인식 기술과 이미지 세그멘테이션 기술의 특징 비교  "
      ],
      "metadata": {
        "id": "KMlk0qta4_o_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|           | 객체 인식 기술                       | 이미지 세그멘테이션 기술 |\n",
        "|-----------|--------------------------------------|--------------------------|\n",
        "| 목적      | 객체 위치 파악 및 객체별 클래스 분류 | 픽셀별 클래스 분류       |\n",
        "| 결과물    | 각 객체의 위치와 경계                | 세그멘테이션 마스크      |\n",
        "| 특징      | 객체의 크기 및 위치만 인식           | 객체의 정확한 형태까지 인식 |\n",
        "| 활용 사례 | 얼굴 인식, 차량 감지                 | 의료 이미지상의 병변 인식, 도로 차선 인식 |\n"
      ],
      "metadata": {
        "id": "MEYlBHzHUZ_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 알아야 하는 기술 키워드\n"
      ],
      "metadata": {
        "id": "Jp0j34_L5dqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **세그멘테이션 마스크(Segmentation Mask)**는 세그멘테이션의 결과물을 의미  \n",
        "세그멘테이션 마스크는 원본 이미지와 같은 크기를 가지며, 각 픽셀이 어떤 클래스에 속하는지를 나타내는 정보를 가지고 있음\n",
        "\n",
        "> **바운딩 박스(Bounding Box)**는 이미지 내의 관심 객체 주위를 사각형으로 둘러싸는 것을 의미  \n",
        "주로 이미지 내 특정 객체의 위치와 크기를 나타내는 데 사용됨\n",
        "\n",
        "> **인터랙티브 세그멘테이션(Interactive Segmentation)**은 이름 그대로 사용자의 상호작용을 바탕으로 하는 세그멘테이션 방식  \n",
        "사용자가 마우스나 터치스크린 등을 이용해서 세그멘테이션하려는 객체의 위치를 입력하면, 이미지에서 입력한 위치의 특정 객체를 분리하는 방식\n",
        "\n",
        "> **파운데이션 모델(Foundation Model)**은 광범위한 사용 사례에 적용할 수 있도록 광범위한 데이터에 대해 훈련된 기계 학습 또는 딥러닝 모델  \n",
        "다양한 사용 사례를 지원할 수 있는 범용 기술"
      ],
      "metadata": {
        "id": "RFmNtPfAV3lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAM - Segment Anything Model\n"
      ],
      "metadata": {
        "id": "AqFWM5xc7Vnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SAM은 메타에서 2023년 4월에 공개한 파운데이션 모델로, 이미지 세그멘테이션에 특화된 파운데이션 모델\n",
        "\n",
        "> 공식 웹사이트: https://segment-anything.com/\n",
        "\n",
        "- SAM은 한 번의 클릭으로 이미지에 있는 모든 객체를 잘라낼 수 있는, 상호작용이 가능한 이미지 세그멘테이션 모델  \n",
        "- SAM은 이미지 약 1,100만 개의 이미지와 10억 개의 마스크 데이터셋을 학습함  \n",
        "- 이미지 내의 대표적인 객체뿐 아니라 상대적으로 작은 객체도 정밀하게 세그멘테이션 가능\n",
        "- 세그멘테이션 수행방식은 이미지 외에 **세그멘테이션 프롬프트**라는 입력을 추가로 받음\n",
        "\n",
        "> **세그멘테이션 프롬프트(Segmentation Prompt)**는 세그멘테이션 영역을 지정하는 행위로 이미지의 특정 위치에 점을 찍거나, 특정 객체를 박스로 표시하는 것 등을 의미함"
      ],
      "metadata": {
        "id": "vpFeZGsLWwpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAM의 구조\n"
      ],
      "metadata": {
        "id": "R4Fw0hKo9Sed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **이미지 인코더**: 이미지를 입력값으로 받으면 이미지의 주요 특징을 추출하고 추출한 특징을 저차원화한 이미지 특징 임베딩을 출력함\n",
        "\n",
        "2. **프롬프트 인코더**: 세그멘테이션 프롬프트를 입력값으로 받으면 프롬프트 임베딩을 출력함\n",
        "\n",
        "3. **마스크 디코더**: 이미지 임베딩과 프롬프트 임베딩을 입력값으로 받아 세그멘테이션 마스크를 출력함"
      ],
      "metadata": {
        "id": "DVMSHZQndlb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAM의 출력\n"
      ],
      "metadata": {
        "id": "pPC9UYDI_8mw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SAM 모델의 추론 결과로 3개의 세그멘테이션 마스크를 출력함\n",
        "\n",
        "- 세그멘테이션 프롬프트만으로는 사용자가 원하는 세그멘테이션을 결과를 정확히 판단할 수 없음\n",
        "- 예를 들어, SAM이 사람의 손 부분의 좌표를 세그멘테이션 프롬프트로 받았을 때, 실제 사용자가 원하는 세그멘테이션 영역이 손인지, 팔인지, 사람 전체인지 명확하게 알 수 없음\n",
        "- SAM은 이러한 모호성을 해결하기 위해 **전체, 부분, 세부 부분**의 세 개의 세그멘테이션 마스크를 출력으로 주고, 그와 동시에 각 마스크에 대한 품질 점수를 함께 출력함"
      ],
      "metadata": {
        "id": "aqdjCwVoaKl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAMPredictor\n"
      ],
      "metadata": {
        "id": "enuZlkyVBvA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- SAM은 공식 리포지토리에서 라이브러리 형태로 사전 학습 모델을 재공함\n",
        "\n",
        "- **SAMPredictor**는 라이브러리에서 제공하는 클래스 중 하나로, 이미지와 세그멘테이션 프롬프트(점, 박스)를 입력받아 세그멘테이션 마스크를 출력하는 기능 제공\n",
        "\n"
      ],
      "metadata": {
        "id": "8SattA4faMOi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iywN7glq5cbS"
      },
      "source": [
        "# SAM 예제 코드\n",
        "\n",
        "Colab 환경에서 SAM 모델을 사용해 이미지에 클릭한 위치의 객체를 segmentation 하는 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JXidjhV5cbV"
      },
      "source": [
        "## 패키지 및 예제 데이터 다운로드하기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "예제를 실행시키기 위해 필요한 파이썬 패키지 설치 및 예제로 사용할 이미지 다운로드  \n",
        "*(Colab에서 실행하지 않는 경우 이 셀은 실행하지 않음)*"
      ],
      "metadata": {
        "id": "9Z6BUN1yghr2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeCFmAzt5cbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425701f0-6de8-4035-c488-d5def167bbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-14 05:26:33--  https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/requirements-colab.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147 [text/plain]\n",
            "Saving to: ‘requirements-colab.txt.1’\n",
            "\n",
            "\rrequirements-colab.   0%[                    ]       0  --.-KB/s               \rrequirements-colab. 100%[===================>]     147  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-14 05:26:33 (10.8 MB/s) - ‘requirements-colab.txt.1’ saved [147/147]\n",
            "\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git (from -r requirements-colab.txt (line 2))\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-rihs38qb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-rihs38qb\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycocotools==2.0.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 3)) (2.0.6)\n",
            "Requirement already satisfied: gradio==3.40.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements-colab.txt (line 6)) (3.40.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (23.2.1)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.10.10)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.115.5)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: gradio-client>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.26.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.3.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (10.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.0.17)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.32.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.40.0->-r requirements-colab.txt (line 6)) (11.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.4.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.16.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (4.66.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (8.1.7)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.41.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.21.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0.6->-r requirements-colab.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.40.0->-r requirements-colab.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp~=3.0->gradio==3.40.0->-r requirements-colab.txt (line 6)) (0.2.0)\n",
            "mkdir: cannot create directory ‘examples’: File exists\n",
            "--2024-11-14 05:26:41--  https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/examples/dog.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 221810 (217K) [image/jpeg]\n",
            "Saving to: ‘dog.jpg.1’\n",
            "\n",
            "dog.jpg.1           100%[===================>] 216.61K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-11-14 05:26:41 (43.2 MB/s) - ‘dog.jpg.1’ saved [221810/221810]\n",
            "\n",
            "--2024-11-14 05:26:41--  https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/examples/mannequin.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 478925 (468K) [image/jpeg]\n",
            "Saving to: ‘mannequin.jpg.1’\n",
            "\n",
            "mannequin.jpg.1     100%[===================>] 467.70K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-11-14 05:26:41 (75.6 MB/s) - ‘mannequin.jpg.1’ saved [478925/478925]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/requirements-colab.txt\n",
        "!pip install -r requirements-colab.txt\n",
        "\n",
        "# 예제 이미지 다운로드\n",
        "!mkdir examples\n",
        "!cd examples && wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/examples/dog.jpg\n",
        "!cd examples && wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/examples/mannequin.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usi6EwlW5cbW"
      },
      "source": [
        "## 패키지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421JCIJ_5cbW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from segment_anything import SamPredictor, sam_model_registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMejIdd75cbX"
      },
      "source": [
        "## 사전 학습 모델 불러오기\n",
        "\n",
        "[Segment Anything 라이브러리](https://github.com/facebookresearch/segment-anything)의 `SamPredictor` Class를 이용해 사전 학습된 SAM 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUOxA-sG5cbX"
      },
      "outputs": [],
      "source": [
        "# 변수 생성\n",
        "CHECKPOINT_PATH = os.path.join(\"checkpoint\")\n",
        "CHECKPOINT_NAME = \"sam_vit_h_4b8939.pth\"\n",
        "CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE55g0vo5cbX"
      },
      "outputs": [],
      "source": [
        "# 디렉토리 생성\n",
        "if not os.path.exists(CHECKPOINT_PATH):\n",
        "    os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "checkpoint = os.path.join(CHECKPOINT_PATH, CHECKPOINT_NAME)\n",
        "if not os.path.exists(checkpoint):\n",
        "    urllib.request.urlretrieve(CHECKPOINT_URL, checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-J3ryAs5cbX"
      },
      "outputs": [],
      "source": [
        "# 사전 학습된 모델 다운로드 및 SamPredictor 생성\n",
        "sam = sam_model_registry[\"vit_h\"](checkpoint=checkpoint).to(DEVICE)\n",
        "predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie2ZfQZP5cbY"
      },
      "source": [
        "## 예제 이미지 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36j-hpo45cbY"
      },
      "outputs": [],
      "source": [
        "# 예제 이미지 open\n",
        "IMAGE_PATH = \"examples/mannequin.jpg\"\n",
        "image = cv2.imread(IMAGE_PATH, cv2.IMREAD_COLOR)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbHSNPz_5cbY"
      },
      "outputs": [],
      "source": [
        "# 예제 이미지 시각화\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"on\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCIPEaI65cbY"
      },
      "source": [
        "## 포인트 좌표 입력 만들기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "원하는 위치의 객체를 세그멘테이션 하기 위한 세그멘테이션 프롬프트로, Point의 좌표를 전달\n",
        "\n",
        "- point_coords: Point 좌표 (x, y)\n",
        "- points_labels: Point의 타입  \n",
        "Point 위치의 객체를 선택하려면 Positive Click(1)로 설정"
      ],
      "metadata": {
        "id": "Q1N2V1mkgdCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GQkI0hI5cbY"
      },
      "outputs": [],
      "source": [
        "# 포인트 좌표 임의 설정\n",
        "point_coords = np.array([[1720, 230]])\n",
        "points_labels = np.array([1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23trjJSQ5cbZ"
      },
      "outputs": [],
      "source": [
        "# 포인트 위치 시각화 (녹색 원으로 표시됨)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "plt.gca().scatter(\n",
        "    point_coords[0, 0],\n",
        "    point_coords[0, 1],\n",
        "    color=\"green\",\n",
        "    marker=\"o\",\n",
        "    s=200,\n",
        "    edgecolor=\"white\",\n",
        "    linewidth=1.25,\n",
        ")\n",
        "plt.axis(\"on\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbOQG-pg5cbZ"
      },
      "source": [
        "## SAM 모델 추론하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "predictor의 predict 함수를 통해 추론한 결과로 출력되는 정보들\n",
        "- masks: 입력한 정보에 대한 3개의 세그멘테이션 마스크\n",
        "- scores: 3개의 세그멘테이션 마스크의 퀄리티에 대한 모델의 평가 점수  \n",
        "점수가 가장 높을수록 퀄리티가 높은 마스크임\n",
        "- low_res_logits: 저해상도 mask 출력 *(이 예제에서는 사용하지 않음)*"
      ],
      "metadata": {
        "id": "ssGHjcfDge9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBfJDR0P5cbZ"
      },
      "outputs": [],
      "source": [
        "# predictor에 이미지 입력 + 세그멘테이션 프롬프트(포인트) 입력하여 추론\n",
        "predictor.set_image(image)\n",
        "masks, scores, _ = predictor.predict(point_coords, points_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u8xEROZ5cbZ"
      },
      "outputs": [],
      "source": [
        "# 추론 결과 마스크 시각화\n",
        "for i, mask in enumerate(masks):\n",
        "    print(f\"Mask {i}\")\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(mask)\n",
        "    plt.axis(\"on\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaJNwbYd5cbZ"
      },
      "outputs": [],
      "source": [
        "# 세그멘테이션 마스크가 이미지의 어느 부분을 나타내는지 시각화\n",
        "color = np.array([30/255, 144/255, 255/255, 0.5])\n",
        "\n",
        "for mask in masks:\n",
        "    mask_image = np.expand_dims(mask, axis=-1) * color.reshape(1, 1, -1)\n",
        "    mask_image = (mask_image * 255).astype(np.uint8)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(mask_image)\n",
        "    plt.axis(\"on\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW40jebr5cbZ"
      },
      "source": [
        "## 평가 점수를 이용해 세그멘테이션 마스크 선택하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Cg-ipB5cbZ"
      },
      "outputs": [],
      "source": [
        "# 각 세그멘테이션 마스크에 대한 평가 점수 출력\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxrh2ILj5cbZ"
      },
      "outputs": [],
      "source": [
        "# 가장 높은 평가 점수를 가진 세그멘테이션 마스크를 골라 시각화\n",
        "mask = masks[np.argmax(scores)]\n",
        "\n",
        "color = np.array([30/255, 144/255, 255/255, 0.5])\n",
        "mask_image = np.expand_dims(mask, axis=-1) * color.reshape(1, 1, -1)\n",
        "mask_image = (mask_image * 255).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image)\n",
        "plt.imshow(mask_image)\n",
        "plt.axis(\"on\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 세그멘테이션 서비스 구현"
      ],
      "metadata": {
        "id": "-RowEgiVaXRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAM 서비스 만들기  \n",
        "https://drive.google.com/file/d/1q2Adc--V0E6ZhSsj6hu2Fd9-_4isvLBC/view?usp=sharing"
      ],
      "metadata": {
        "id": "Syt81gHgaTkf"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "3m-cS0_-3yyt",
        "6ewwyYLcWo8p",
        "KMlk0qta4_o_",
        "Jp0j34_L5dqW",
        "AqFWM5xc7Vnm",
        "R4Fw0hKo9Sed",
        "pPC9UYDI_8mw",
        "enuZlkyVBvA6",
        "iywN7glq5cbS",
        "9JXidjhV5cbV",
        "usi6EwlW5cbW",
        "EMejIdd75cbX",
        "Ie2ZfQZP5cbY",
        "NCIPEaI65cbY",
        "DbOQG-pg5cbZ",
        "bW40jebr5cbZ",
        "-RowEgiVaXRU"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}